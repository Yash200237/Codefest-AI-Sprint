{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f0ed51e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dulak\\AppData\\Local\\Temp\\ipykernel_21296\\1202135216.py:60: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  y[col] = output_encoders[col].fit_transform(y[col])\n",
      "C:\\Users\\dulak\\AppData\\Local\\Temp\\ipykernel_21296\\1202135216.py:60: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  y[col] = output_encoders[col].fit_transform(y[col])\n",
      "C:\\Users\\dulak\\AppData\\Local\\Temp\\ipykernel_21296\\1202135216.py:60: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  y[col] = output_encoders[col].fit_transform(y[col])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Trained\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "Product: top_product\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        29\n",
      "           1       1.00      1.00      1.00        35\n",
      "           2       1.00      1.00      1.00        27\n",
      "           3       1.00      1.00      1.00        27\n",
      "           4       1.00      1.00      1.00        39\n",
      "           5       1.00      1.00      1.00        41\n",
      "           6       1.00      1.00      1.00        31\n",
      "           7       1.00      1.00      1.00        31\n",
      "\n",
      "    accuracy                           1.00       260\n",
      "   macro avg       1.00      1.00      1.00       260\n",
      "weighted avg       1.00      1.00      1.00       260\n",
      "\n",
      "\n",
      "Product: second_product\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        29\n",
      "           1       1.00      1.00      1.00        27\n",
      "           2       1.00      1.00      1.00        41\n",
      "           3       1.00      1.00      1.00        31\n",
      "           4       1.00      1.00      1.00        27\n",
      "           5       1.00      1.00      1.00        39\n",
      "           6       1.00      1.00      1.00        35\n",
      "           7       1.00      1.00      1.00        31\n",
      "\n",
      "    accuracy                           1.00       260\n",
      "   macro avg       1.00      1.00      1.00       260\n",
      "weighted avg       1.00      1.00      1.00       260\n",
      "\n",
      "\n",
      "Product: third_product\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        35\n",
      "           1       1.00      1.00      1.00        31\n",
      "           2       1.00      1.00      1.00        27\n",
      "           3       1.00      1.00      1.00        31\n",
      "           4       1.00      1.00      1.00        29\n",
      "           5       1.00      1.00      1.00        27\n",
      "           6       1.00      1.00      1.00        39\n",
      "           7       1.00      1.00      1.00        41\n",
      "\n",
      "    accuracy                           1.00       260\n",
      "   macro avg       1.00      1.00      1.00       260\n",
      "weighted avg       1.00      1.00      1.00       260\n",
      "\n",
      "\n",
      "Sample Predictions:\n",
      "  top_product second_product third_product\n",
      "0       Juice           Soda         Water\n",
      "1        Milk         Cheese        Yogurt\n",
      "2        Rice          Wheat          Oats\n",
      "3      Shrimp           Fish          Crab\n",
      "4       Juice           Soda         Water\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, OrdinalEncoder, LabelEncoder\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Load dataset\n",
    "data = pd.read_csv('all_combinations_with_ranked_products.csv')  # Update with your file path\n",
    "print(\"Dataset Loaded\")\n",
    "\n",
    "# Inputs: scale, location, storage_capacity, quality_preference, product_category, sustainability_focus\n",
    "# Outputs: top_product, second_product, third_product\n",
    "\n",
    "input_columns = [\n",
    "    'scale', 'location', 'storage_capacity', 'quality_preference', \n",
    "    'product_category', 'sustainability_focus'\n",
    "]\n",
    "output_columns = ['top_product', 'second_product', 'third_product']\n",
    "\n",
    "# Define columns for preprocessing\n",
    "ordinal_columns = ['scale', 'storage_capacity', 'quality_preference']\n",
    "categorical_columns = ['location', 'product_category']\n",
    "numerical_columns = ['sustainability_focus']\n",
    "\n",
    "# Define pipelines for each feature type\n",
    "ordinal_pipeline = Pipeline(steps=[('ordinal', OrdinalEncoder())])\n",
    "categorical_pipeline = Pipeline(steps=[('onehot', OneHotEncoder(drop='first', sparse_output=False))])\n",
    "numerical_pipeline = Pipeline(steps=[('scaler', StandardScaler())])\n",
    "\n",
    "# Combine preprocessing steps into a ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('ord', ordinal_pipeline, ordinal_columns),\n",
    "        ('cat', categorical_pipeline, categorical_columns),\n",
    "        ('num', numerical_pipeline, numerical_columns),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Apply preprocessing pipeline to features\n",
    "X = data[input_columns]\n",
    "y = data[output_columns]\n",
    "\n",
    "# Preprocess the features\n",
    "X_transformed = preprocessor.fit_transform(X)\n",
    "\n",
    "# Convert preprocessed features into a DataFrame\n",
    "preprocessed_columns = (\n",
    "    ordinal_columns + \n",
    "    list(preprocessor.named_transformers_['cat'].get_feature_names_out(categorical_columns)) + \n",
    "    numerical_columns\n",
    ")\n",
    "X_processed = pd.DataFrame(X_transformed, columns=preprocessed_columns, index=X.index)\n",
    "\n",
    "# Label encode output products\n",
    "output_encoders = {col: LabelEncoder() for col in output_columns}\n",
    "for col in output_columns:\n",
    "    y[col] = output_encoders[col].fit_transform(y[col])\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_processed, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Multi-label classification with Random Forest\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "multi_output_model = MultiOutputClassifier(rf_model)\n",
    "\n",
    "# Train the model\n",
    "multi_output_model.fit(X_train, y_train)\n",
    "print(\"Model Trained\")\n",
    "\n",
    "# Predictions\n",
    "y_pred = multi_output_model.predict(X_test)\n",
    "\n",
    "# Decode predictions back to original labels\n",
    "decoded_predictions = pd.DataFrame(y_pred, columns=output_columns)\n",
    "for col in output_columns:\n",
    "    decoded_predictions[col] = output_encoders[col].inverse_transform(decoded_predictions[col])\n",
    "\n",
    "# Evaluation\n",
    "print(\"\\nClassification Report:\")\n",
    "for i, col in enumerate(output_columns):\n",
    "    print(f\"\\nProduct: {col}\")\n",
    "    print(classification_report(y_test[col], y_pred[:, i]))\n",
    "\n",
    "# Display sample predictions\n",
    "print(\"\\nSample Predictions:\")\n",
    "print(decoded_predictions.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472549b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc2b7a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
